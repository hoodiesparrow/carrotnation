## ğŸ’» ë¹…ë°ì´í„° ë¶„ì„ ì‚¬ì „í•™ìŠµ 2ê°•



### Paritioner class

- Map í•¨ìˆ˜ì˜ ì¶œë ¥ì¸ (key, value)ìŒì´ keyì— ì˜í•´ì„œ ì–´ëŠ Reducer(ë¨¸ì‹ )ìœ¼ë¡œ ë³´ë‚´ì§ˆ ê²ƒì¸ì§€ë¥¼ ì •í•´ì§€ëŠ”ë° ì´ëŸ¬í•œ ê²°ì •ì„ ì •ì˜í•˜ëŠ” Class

- í•˜ë‘¡ì˜ ê¸°ë³¸ íƒ€ì…ì€ Hash í•¨ìˆ˜ê°€ Defaultë¡œ ì œê³µë˜ê³  ìˆì–´ì„œ Keyì— ëŒ€í•œ í•´ì‹œ ê°’ì— ë”°ë¼

  ì–´ëŠ” Reducer(ë¨¸ì‹ )ìœ¼ë¡œ ë³´ë‚¼ì§€ë¥¼ ê²°ì •í•œë‹¤.

  ![partitioner.PNG](img/partitioner.PNG)

  ```java
  import org.apache.hadoop.mapreduce.Partitioner;
  
  public static class MyPartitioner extends Partitioner <IntWritable, Text>{
  				@Override
  				public int getPartition(IntWritable key, Text value, int numPartitions){
  							int nbOccurences = key.get(); // í‚¤ ê°’ì„ ë½‘ì•„ëƒ„
  							if(nbOccurences <= 30) return 0;  //0ë²ˆ ë¨¸ì‹ 
  							else return 1;                    //1ë²ˆ ë¨¸ì‹ 
  				}
  }
  ```

  Main í•¨ìˆ˜ì— ì¶”ê°€

  ```java
  job.setPartitionerClass(MyPartitioner.class);
  ```

### í•˜ë‘¡ ì‹¤í–‰ ê¸°ë³¸ ëª…ë ¹ì–´

```java
$ ant
$ hdfs dfs -rm -r wordcount_test_out
$ hadoop jar ssafy.jar wordcountsort wordcount_test wordcount_test_out
$ hdfs dfs -cat wordcount_test_out/part-r-00000 | more
$ hdfs dfs -cat wordcount_test_out/part-r-00001 | more
```

### hadoop Connection refused Error ì‹œ check

```java
$ jps //ì‹¤í–‰í›„ hadoop node ì˜¬ë¼ê°€ìˆëŠ”ì§€ í™•ì¸
$ start-dfs.sh //ë§Œì¼ ì—†ë‹¤ë©´ ì‹¤í–‰
```

### Inverted Index

- keyê°’ì´ ì–´ëŠ ë¬¸ì„œì— ì¡´ì¬í•˜ëŠ” ì–´ëŠ ìœ„ì¹˜ì— ìˆëŠ”ì§€ list

![Invertedlist.PNG](img/Invertedlist.PNG)





